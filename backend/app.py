# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q1BUGm7Ibpw881UIQEETNU21cZi22_m3
"""

!pip install flask pyngrok torch diffusers transformers accelerate safetensors --quiet

from pyngrok import conf

# Paste your authtoken from the ngrok dashboard here
conf.get_default().auth_token = "2vG8GeOrRUeV7eOLQu13S8YNLU1_6tA2eXeDG4aDrStMBCkgG"

pip install flask-cors

from flask import Flask, request, jsonify
from flask_cors import CORS
from diffusers import DiffusionPipeline
import torch
import base64
from io import BytesIO
from pyngrok import ngrok

app = Flask(__name__)
CORS(app)  # Enable CORS for all origins

# Use GPU if available
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Load Base & Refiner Models
sdxl_base = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16"
).to(DEVICE)

sdxl_refiner = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=sdxl_base.text_encoder_2,
    vae=sdxl_base.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16"
).to(DEVICE)

@app.route("/generate", methods=["POST"])
def generate_image():
    data = request.json
    prompt = data.get("prompt", "A beautiful landscape")
    model_type = data.get("model", "standard").lower()

    try:
        if model_type == "standard":
            image = sdxl_base(prompt=prompt, width=512, height=512).images[0]
        elif model_type == "hd":
            n_steps = 40
            high_noise_frac = 0.8

            latent_image = sdxl_base(
                prompt=prompt,
                num_inference_steps=n_steps,
                denoising_end=high_noise_frac,
                output_type="latent"
            ).images

            image = sdxl_refiner(
                prompt=prompt,
                num_inference_steps=n_steps,
                denoising_start=high_noise_frac,
                image=latent_image
            ).images[0]
        else:
            return jsonify({"error": "Invalid model type"}), 400

        # Encode image
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        img_str = base64.b64encode(buffer.getvalue()).decode("utf-8")
        return jsonify({"image": img_str})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Run server & expose via ngrok
public_url = ngrok.connect(5000)
print("Public URL:", public_url)
app.run(port=5000)

